{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install torch-fidelity"
      ],
      "metadata": {
        "id": "HbHLnqxtEmyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vcz9H9p0B--a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make your network\n",
        "here we consider a FFNN with two hidden layers, one input and one output\n",
        "the activation func is a sigmoid function.\n",
        "We consider that we want to create a linear regression. So, we have one input as x, and the output as y values"
      ],
      "metadata": {
        "id": "C-rnIlSbCVDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,Ni=1, Nh1=128, Nh2=256, No=1):\n",
        "    super().__init__()\n",
        "\n",
        "    print(\"network initializaiton\")\n",
        "\n",
        "    self.fc1 = nn.Linear(Ni,Nh1)\n",
        "    self.fc2 = nn.Linear(Nh1,Nh2)\n",
        "    self.out = nn.Linear(Nh2,No)\n",
        "    self.act = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x,additional_out = False):\n",
        "    x = self.act(self.fc1(x))\n",
        "    x = self.act(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "CxtlMFhBCnOC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import and process the data\n",
        "Consider we have an excel data with the x column as input and the y column as the output or the labels.\n",
        "We have to do three things:\n",
        "1. reading teh data\n",
        "2. convert the data to the tensors\n",
        "3. load the in the batches using the dataloader. The suggested value for the batch number is a number like: $ 2^n$\n",
        "for example the numbers like 2, 4, 8, 16, 32, 64, 128, ... are good numbers for the batch size.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lqtlroL8CrHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CsvDataset(Dataset):\n",
        "  def __init__(self,csv_file,transform = None):\n",
        "    self.transform = transform\n",
        "    self.data = []\n",
        "    with open(csv_file, newline='') as csvfile:\n",
        "      lines = csvfile.read().split()\n",
        "\n",
        "    for line in lines:\n",
        "      sample = line.split(',')\n",
        "      if (sample[0]) != 'x'and  len(sample) >= 2    :\n",
        "        self.data.append((float(sample[0]),float(sample[1])))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    sample = self.data[idx]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample"
      ],
      "metadata": {
        "id": "EcmOMg1vD33m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "  def __call__(self,sample):\n",
        "    x,y = sample\n",
        "    return(torch.tensor(x).float(),\n",
        "           torch.tensor(y).float())"
      ],
      "metadata": {
        "id": "JUQGQR3OD_Wh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed_transform = transforms.Compose([ToTensor()])\n",
        "\n",
        "train_dataset = CsvDataset('train.csv',transform=composed_transform)\n",
        "val_dataset = CsvDataset('validation.csv',transform=composed_transform)"
      ],
      "metadata": {
        "id": "6mkGwizWEBTU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloader\n",
        "for the dataloader:\n",
        "\n",
        "enable shuffling (needed only fro train data_\n",
        "try different values for batch size"
      ],
      "metadata": {
        "id": "Is1zCv-yEFC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,batch_size = 1024,shuffle=True,num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size = len(val_dataset),shuffle=False,num_workers=0)"
      ],
      "metadata": {
        "id": "OcNqlFBNEGuv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Choose the GPU device is available\n",
        " Check if the GPU is available\n"
      ],
      "metadata": {
        "id": "na0k2rWSFM4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU is available\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Training device: {device}\")"
      ],
      "metadata": {
        "id": "q4TU1pTwFQiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e01488d-2f35-40fc-b99c-8451027c85e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch lightening"
      ],
      "metadata": {
        "id": "R82r0QlRETyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitFNN(pl.LightningModule):\n",
        "  def __init__(\n",
        "        self,\n",
        "        lr: float = 1e-3,\n",
        "        b1: float = 0.5,\n",
        "        b2: float = 0.999\n",
        "\n",
        "    ):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    #network\n",
        "    self.net = Net()\n",
        "\n",
        "    #define loss\n",
        "    self.loss_fn = nn.MSELoss()\n",
        "\n",
        "\n",
        "    #forward path\n",
        "  def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n",
        "  #config the optimizer\n",
        "  def configure_optimizers(self):\n",
        "      lr = self.hparams.lr\n",
        "      b1 = self.hparams.b1\n",
        "      b2 = self.hparams.b2\n",
        "\n",
        "      optimizer = torch.optim.Adam(self.net.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "      return optimizer\n",
        "\n",
        "  #training step\n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "      x_batch = train_batch[0].unsqueeze(0)\n",
        "      x_batch = torch.transpose(x_batch,0,1)\n",
        "      label_batch = train_batch[1].unsqueeze(0)\n",
        "      label_batch = torch.transpose(label_batch,0,1)\n",
        "      out = self.net(x_batch)\n",
        "      loss = self.loss_fn(out,label_batch)\n",
        "      self.log(\"train_loss\",loss, prog_bar=True)\n",
        "      return {'loss': loss}\n",
        "  #validation step\n",
        "  def validation_step(self,valid_batch,batch_idx):\n",
        "      x_batch = valid_batch[0].unsqueeze(0)\n",
        "      x_batch = torch.transpose(x_batch,0,1)\n",
        "      label_batch = valid_batch[1].unsqueeze(0)\n",
        "      label_batch = torch.transpose(label_batch,0,1)\n",
        "      out = self.net(x_batch)\n",
        "      loss = self.loss_fn(out,label_batch)\n",
        "      self.log(\"val_loss\",loss, prog_bar=True)\n",
        "      return {'validation_loss': loss}"
      ],
      "metadata": {
        "id": "Oxd_OuumEXEh"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "\n",
        "class History(Callback):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "\n",
        "        dirpath:str ='/content/',\n",
        "        filename:str = 'history.json',\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.t_loss = []\n",
        "        self.v_loss = []\n",
        "        self.dirpath = dirpath\n",
        "        self.filename = filename\n",
        "        self.path = os.path.join(dirpath,filename)\n",
        "        self._init_dict()\n",
        "        self._init_lists()\n",
        "\n",
        "    def _init_dict(self):\n",
        "        self.dict = {'train_loss':[],\n",
        "                     'val_loss':[]}\n",
        "        os.makedirs(self.dirpath, exist_ok=True)\n",
        "        with open(self.path,'w') as f:\n",
        "            json.dump(self.dict,f)\n",
        "\n",
        "    def _init_lists(self):\n",
        "        self.t_loss = []\n",
        "        self.v_loss = []\n",
        "\n",
        "\n",
        "    def on_train_batch_end(self,trainer, pl_module,outputs,batch,batch_idx,unused=0):\n",
        "        self.t_loss.append(outputs['loss'].item())\n",
        "\n",
        "\n",
        "    def on_validation_batch_end(self,trainer, pl_module,outputs,batch,batch_idx):\n",
        "        self.v_loss.append(outputs['validation_loss'].item())\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self,trainer,pl_module):\n",
        "        self.dict['train_loss'].append(float(torch.mean(torch.tensor(self.t_loss))))\n",
        "        with open(self.path,'w') as f:\n",
        "            json.dump(self.dict,f)\n",
        "        self.t_loss = []\n",
        "\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        self.dict['val_loss'].append(float(np.mean(self.v_loss)))\n",
        "        with open(self.path,'w') as f:\n",
        "            json.dump(self.dict,f)\n",
        "        self.v_loss = []\n"
      ],
      "metadata": {
        "id": "syhKEFyPYeUC"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_dir = \"/content\"\n",
        "call_back = History(dirpath =\"/content\")\n",
        "\n",
        "trainer = pl.Trainer(default_root_dir=experiment_dir,\n",
        "                     #gpus=1,\n",
        "                     precision=16,\n",
        "                     max_epochs=100,\n",
        "                     val_check_interval=1, #check_validation_accuracy\n",
        "                     callbacks=[call_back],\n",
        "                     num_sanity_val_steps=0,\n",
        "                     #logger=logger,\n",
        "                     )\n",
        "net = LitFNN()\n",
        "trainer.fit(net, train_dataloader,val_dataloader)"
      ],
      "metadata": {
        "id": "yw60b2R1cM9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GqEeJC7WEMmt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}